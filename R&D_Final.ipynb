{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R&D Capital Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peyton Lewis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and Clean Fama French Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and set the index to column renamed as DATE\n",
    "fama_data = pd.read_csv('FFFactors2.csv')\n",
    "fama_data = fama_data.set_index('Unnamed: 0')\n",
    "fama_data.index.name = 'DATE'\n",
    "\n",
    "# Transform fama date format to datetime object and reformat as year-month from format without a dash in between \n",
    "fama_data.index = pd.to_datetime(fama_data.index, format = '%Y%m')\n",
    "fama_data.index = fama_data.index.strftime('%Y-%m')\n",
    "\n",
    "# Divide all columns by 100 because they are in percent format originally \n",
    "fama_data = fama_data/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and Clean Monthly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the monthly data and set date to datetime \n",
    "monthly_data = pd.read_csv('monthly_data.csv') \n",
    "monthly_data['date'] = pd.to_datetime(monthly_data['date'])\n",
    "monthly_data.sort_values(by='date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to help remove non-numeric returns from monthly_data\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True  # returns True if numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply numeric filter to monthly_data\n",
    "numeric_filter = monthly_data['RET'].map(is_float)\n",
    "monthly_data = monthly_data[numeric_filter]\n",
    "\n",
    "# Drop any Nans for returns column and convert them to floats\n",
    "monthly_data = monthly_data.dropna(subset = ['RET'])\n",
    "monthly_data['RET'] = monthly_data['RET'].astype(float)\n",
    "\n",
    "# Compute montly ME as shares outstanding * abs(price)\n",
    "monthly_data['MONTHLY_ME'] = monthly_data['SHROUT'].astype(float) * abs(monthly_data['PRC'].astype(float))\n",
    "\n",
    "# Shift MONTHLY_ME by one month and group by PERMNO so use ME at time t-1 in the value-weighting later\n",
    "monthly_data = monthly_data.sort_values(['date','PERMNO'])\n",
    "monthly_data['SHIFTED_MONTHLY_ME'] = monthly_data.groupby('PERMNO')['MONTHLY_ME'].shift(1)\n",
    "monthly_data = monthly_data.dropna(subset = ['SHIFTED_MONTHLY_ME'])  # drop the Nas that result from shifting monthly ME (does not affect results substantially)\n",
    "\n",
    "# Filter out returns < -1 and slice to be appropriate time window\n",
    "returns_filter = (monthly_data['RET'] > -1) \n",
    "monthly_data = monthly_data[returns_filter]\n",
    "monthly_data = monthly_data[(monthly_data['date'] >= '1975-01-01') & (monthly_data['date'] <= '2022-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting the RF rate from the montly returns at beginning so always using excess returns \n",
    "\n",
    "# Creating this date so that I can merge on the date in the Fama French data (same year-month format)\n",
    "monthly_data['YEAR_MONTH'] = monthly_data['date'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "\n",
    "# Merge fama and monthly data\n",
    "monthly_data = monthly_data.merge(fama_data, left_on = 'YEAR_MONTH', right_on = 'DATE', how = 'left')\n",
    "\n",
    "# Subtract the RF rate from all returns\n",
    "monthly_data['ORIG_RET'] = monthly_data['RET'] * 1   # kept to check to see if rf was subtracted correctly\n",
    "monthly_data['RET'] = monthly_data['ORIG_RET'] - monthly_data['RF']  # this column will be used in remainder of calculations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in and Cleaning the Annual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the annual financial data and set date to datetime \n",
    "annual_financials = pd.read_csv('annual_financials.csv')\n",
    "annual_financials['datadate'] = pd.to_datetime(annual_financials['datadate'])\n",
    "\n",
    "# Sort by date\n",
    "annual_financials.sort_values(by='datadate', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the Data\n",
    "\n",
    "# Filter out the sic codes between 6000 and 6999\n",
    "sic_filter = (annual_financials['sic'] >= 6000) & (annual_financials['sic'] <= 6999)\n",
    "annual_financials = annual_financials[~sic_filter]\n",
    "\n",
    "# Filter out fund exchange codes to be between 11 and 19 only\n",
    "exch_filter = (annual_financials['exchg'] >= 11) & (annual_financials['exchg'] <= 19)\n",
    "annual_financials = annual_financials[exch_filter]\n",
    "\n",
    "# Fill NaN with 0 in xrd column \n",
    "annual_financials['xrd'].fillna(0, inplace=True)\n",
    "\n",
    "# Create ME Column (shares * price)\n",
    "annual_financials['ME'] = annual_financials['csho'] * annual_financials['prcc_f']\n",
    "\n",
    "# Drop the columns that are not needed\n",
    "annual_financials = annual_financials.drop(['indfmt', 'consol', 'popsrc', 'datafmt', 'costat'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look Ahead Bias: Shift all dates by 90 days in annual financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift all datadates by 90 days in annual financials\n",
    "annual_financials['datadate'] = annual_financials['datadate'] + pd.DateOffset(days=90)\n",
    "\n",
    "# Filter annual_financials for time 1975-2022 \n",
    "annual_financials = annual_financials[(annual_financials['datadate'] >= '1975-01-01') & (annual_financials['datadate'] <= '2022-01-01')]\n",
    "\n",
    "# Drop Nans in ME\n",
    "annual_financials = annual_financials.dropna(subset = ['ME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Fix Fyear (annual_financials) and (monthly) to correctly merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the annual data the creates YEAR column  \n",
    "def get_year(date):\n",
    "    if date.month >= 4:\n",
    "        return date.year + 1\n",
    "    else:\n",
    "        return date.year \n",
    "\n",
    "# Function for the monthly data the creates YEAR column \n",
    "def get_year_month(date):\n",
    "    if date.month >= 4:\n",
    "        return date.year\n",
    "    else:\n",
    "        return date.year - 1\n",
    "\n",
    "# Apply both functions to the data\n",
    "monthly_data['YEAR'] = monthly_data['date'].apply(get_year_month)\n",
    "annual_financials['YEAR'] = annual_financials['datadate'].apply(get_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology Description: \n",
    "The thought process behind this was that the fyear given in the annual financials would not work for my goal of being able to form the portfolio once a year after the data was shifted 90 days forward. I decided to build my portfolio once a year on every April 1. To get the correct portfolio reconstruction year for every stock, which I defined to be the April 1, YEAR in which the portfolio was made, I created this 'YEAR' column in the functions shown above. This procedure looked different for the annual and monthly data.  <br><br>\n",
    "For the annual data, the following process was used. For dates (post 90 day shift) with months of January, February, or March (months < 4), their 'YEAR' was just the same as the year in their datadate column, because those financials would be available prior to April 1, when that YEAR's portfolio was being built. For months April - December (month >= 4), one was added to their datadate year, because those financials would be the most recently available for the next year's portfolio construction. This was the method to make this 'YEAR' column in the annual financials data. <br><br>\n",
    "In the monthly data, a similar process was used to create the same 'YEAR' column, but with a slightly different logic. If the month was >= 4, YEAR was set equal to the same year of its date and if month < 4, YEAR was set to its date's year - 1. The reason for this was as follows: once a portfolio is constructed for a YEAR, like 2021, it needs to track monthly returns for the next 12 months. For the months April - December (month >= 4), we want these returns available for the 2021 portfolio, which is the year they have in their date. For the months of Jan - March (month < 4) of the next year right before the next portfolio is made, we need those monthly returns, which are in the year 2022. To make them line up with the 2021 YEAR's portfolio, one needed to be subtracted from their dates' year (i.e. 2022 - 1 = 2021). Therefore, for these months, I subtracted 1 from their dates' year to create the 'YEAR' variable. This fascilitated the merging later on. \n",
    "<br><br>\n",
    "Additionally, I chose to rebuild the portfolio every April 1, because the majority of firms had financial year ends in December. This is because with the 90 day shift, their annuals were ready the following 3/31 and would be the \"most recent\" financials available for each portfolio construction on 4/1/YEAR. This assumption was made so that for a majority of the firms, I would have the most recently available financials, and for fewer firms I would be using more \"stale\" financial data. \n",
    "\n",
    "### Disclaimer:\n",
    "Later on in the portfolio construction process, when there is a time window that does not begin exactly at 4/1/YEAR, the assumption that I am making is that that portfolio was indeed constructed on the relevant 4/1/YEAR, and we are tracking its returns for the subsequent months that fall into the desired time window. For example, in the time range 1981.07 - 1999.12, the assumption is that the 1981 portfolio was constructed on 4/1/1981, but we are tracking its returns from July onward until the end of the March of 1984, right before the 1984 porfolio is made. Likewise, in the time slice 2000.01 - 2012.12, for example, the assumption is that the 1999 portfolio (constructed on 4/1/1999), has returns that are being tracked in this time period from January 2000 - March 2000, right before the 2001 portfolio is constructed on 4/1/2001. This assumption is used throughout the portfolio construction processes so that the time windows of the assignment would be aligned with the results, even though I build the portfolios (sort by RD) on every April 1, YEAR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute RDC and RDC/ME for firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set negative xrd values to 0 \n",
    "# I made this assumption because I found 7 rows in the annual data with a negative xrd value; I set these to 0 and proceeded with calculations\n",
    "# I felt as though this would not skew the results drastically; I actually tried both ways in the code and the answers were only off in the 0.0001 place\n",
    "# I decided to keep the code with the negative xrd values set to 0 because a negative R&D expenditure does not make sense\n",
    "# I checked the documentation in WRDS and it does not say anything about negative values for xrd, so I continued with my assumption \n",
    "annual_financials['xrd'] = annual_financials['xrd'].apply(lambda x: 0 if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created rd1 - rd4 using groupby and .shift()\n",
    "rd1 = annual_financials.groupby('GVKEY')['xrd'].shift(1)\n",
    "rd2 = annual_financials.groupby('GVKEY')['xrd'].shift(2)\n",
    "rd3 = annual_financials.groupby('GVKEY')['xrd'].shift(3)\n",
    "rd4 = annual_financials.groupby('GVKEY')['xrd'].shift(4)\n",
    "\n",
    "# Added rd1-rd4 as columns to annual_financials for ease of computing \n",
    "annual_financials['rd1'] = rd1\n",
    "annual_financials['rd2'] = rd2\n",
    "annual_financials['rd3'] = rd3\n",
    "annual_financials['rd4'] = rd4\n",
    "\n",
    "# Set rd1, rd2, rd3 and rd4 Nans to 0\n",
    "annual_financials['rd1'].fillna(0, inplace=True)\n",
    "annual_financials['rd2'].fillna(0, inplace=True)\n",
    "annual_financials['rd3'].fillna(0, inplace=True)\n",
    "annual_financials['rd4'].fillna(0, inplace=True)\n",
    "\n",
    "# Compute rdc \n",
    "annual_financials['rdc'] = annual_financials['xrd'] + 0.8 * annual_financials['rd1'] + 0.6 * annual_financials['rd2'] + 0.4 * annual_financials['rd3'] + 0.2 * annual_financials['rd4']\n",
    "\n",
    "# Compute rdc/ME (normalizing by the market capitalization)\n",
    "annual_financials['rdc/ME'] = annual_financials['rdc'] / annual_financials['ME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Annual and Monthly Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge annual_financials with monthly_data on lpermno and year and permno and year\n",
    "merge = monthly_data.merge(annual_financials, how = 'inner', left_on = ['PERMNO', 'YEAR'], right_on = ['LPERMNO', 'YEAR'])\n",
    "\n",
    "# Remove unneccesary columns \n",
    "merge.drop(columns = ['EXCHCD', 'SICCD', 'TICKER', 'LPERMNO', 'conm', 'curcd', 'csho', 'exchg', 'mkvalt', 'sic', 'fyr'], inplace = True)\n",
    "merge.drop(columns = ['rd1', 'rd2', 'rd3', 'rd4', 'rdc', 'Mkt-RF', 'SMB', 'HML', 'RF'], inplace = True)\n",
    "\n",
    "# Rename columns to more clear names for later use\n",
    "merge.rename({'datadate': 'ANNUAL_DATE'}, axis = 1, inplace = True)\n",
    "merge.rename({'date': 'MONTHLY_DATE'}, axis = 1, inplace = True)\n",
    "merge.rename({'prcc_f': 'ANNUAL_PRICE'}, axis = 1, inplace = True)\n",
    "merge.rename({'PRC': 'MONTHLY_PRICE'}, axis = 1, inplace = True)\n",
    "\n",
    "# Drop duplicates for permno and monthly date (sometimes it was keeping 2 records for a firm in  YEAR, but we want to keep the one with latest financial data each time)\n",
    "# For example for the YEAR 1983, there was a record for a firm for 3/31/1983 and 5/31/1982, which is the same reconsitution YEAR (1983), but we want to keep\n",
    "# the record with the most recently available financial data as of reconstruction on 4/1/YEAR, which is the 3/31/1983 row \n",
    "# This may be the result of a firm switching its fiscal year end midway\n",
    "merge.sort_values(['PERMNO', 'MONTHLY_DATE', 'ANNUAL_DATE'], inplace = True)\n",
    "merge.drop_duplicates(subset = ['PERMNO', 'MONTHLY_DATE'], keep = 'last', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Construction and Returns Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will go once each 'YEAR' and make RD and nonRD dataframe, \n",
    "# then add indicator for porfolio (1-5 and NonRD) and then make df of monthly portfolio returns \n",
    "# for equally weighted or value weighted returns \n",
    "\n",
    "def make_portfolios(merge, start_date, end_date, type_weight) :\n",
    "\n",
    "    # Filter for the year\n",
    "    df = merge[(merge['MONTHLY_DATE'] >= start_date) & (merge['MONTHLY_DATE'] <= end_date)]\n",
    "\n",
    "    # Set up empty df for returns\n",
    "    portfolio_returns = pd.DataFrame()\n",
    "    monthly_me = pd.DataFrame()\n",
    "\n",
    "    # Years to loop through \n",
    "    total_years = df['YEAR'].unique()\n",
    "    \n",
    "    # Sort years \n",
    "    total_years = np.sort(total_years)\n",
    "\n",
    "    # Loop through the years\n",
    "    for year in total_years: \n",
    "       \n",
    "        # Filter for the year\n",
    "        df_year = df[df['YEAR'] == year]\n",
    "\n",
    "        # RD firms will not have zero measure here; NonRD firms will have zero measure\n",
    "        rd = df_year[df_year['rdc/ME'] > 0]\n",
    "        non_rd = df_year[df_year['rdc/ME'] == 0]\n",
    "\n",
    "        # Sort by rdc/ME to make portfolios\n",
    "        rd = rd.sort_values(by = ['rdc/ME'], ascending = False)\n",
    "\n",
    "        # Cut rd firms into 5 bins\n",
    "        rd['bin'] = pd.qcut(rd['rdc/ME'], 5, labels = [1,2,3,4,5])\n",
    "        non_rd['bin'] = 'NonRD'\n",
    "\n",
    "        # Put dataframes back together\n",
    "        joined_df = pd.concat([rd, non_rd])\n",
    "\n",
    "       \n",
    "        # Equal weighted portfolios\n",
    "        if type_weight == 'equal' : \n",
    "\n",
    "            # Calculate portfolio returns and add to df\n",
    "            # Grouped by monthly_date and bin to get an average return for each portfolio for each month in df \n",
    "            # Need to unstack because had hierarchical indices from groupby\n",
    "            portfolio_returns = portfolio_returns.append(joined_df.groupby(['MONTHLY_DATE', 'bin'])['RET'].mean().unstack())    \n",
    "\n",
    "        # Value weighted portfolios \n",
    "        elif type_weight == 'value' : \n",
    "\n",
    "            # Make separate dfs by bin\n",
    "            bin_low = joined_df[joined_df['bin'] == 1]\n",
    "            bin_2 = joined_df[joined_df['bin'] == 2]\n",
    "            bin_3 = joined_df[joined_df['bin'] == 3]\n",
    "            bin_4 = joined_df[joined_df['bin'] == 4]\n",
    "            bin_high = joined_df[joined_df['bin'] == 5]\n",
    "            bin_nonRD = joined_df[joined_df['bin'] == 'NonRD']\n",
    "\n",
    "            # Dataframe of the sum of the lagged ME for the stocks in each portfolio to use as denominator of weights in each period\n",
    "            # Group by monthly_date and bin, then take sum of shifted monthly ME for that combination and store in the df\n",
    "            # Unstack the hierarchical indices \n",
    "            monthly_me = monthly_me.append(joined_df.groupby(['MONTHLY_DATE', 'bin'])['SHIFTED_MONTHLY_ME'].sum().unstack()) \n",
    "\n",
    "\n",
    "            # Bin 1\n",
    "\n",
    "            # Get where the index is equal to the date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_low['MONTHLY_ME_TOTAL'] = bin_low.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 1], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged ME's in that portfolio on that monthly_date\n",
    "            bin_low['weight'] = bin_low['SHIFTED_MONTHLY_ME'] / bin_low['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Bin 2\n",
    "\n",
    "            # Get where the index is equal to the date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_2['MONTHLY_ME_TOTAL'] = bin_2.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 2], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged ME's in that portfolio on that monthly date\n",
    "            bin_2['weight'] = bin_2['SHIFTED_MONTHLY_ME'] / bin_2['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Bin 3\n",
    "            \n",
    "            # Get where the index is equal to the date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_3['MONTHLY_ME_TOTAL'] = bin_3.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 3], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged ME's in that portfolio on that monthly date\n",
    "            bin_3['weight'] = bin_3['SHIFTED_MONTHLY_ME'] / bin_3['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Bin 4\n",
    "            \n",
    "            # Get where the index is equal to the date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_4['MONTHLY_ME_TOTAL'] = bin_4.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 4], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged ME's in that portfolio on that monthly date\n",
    "            bin_4['weight'] = bin_4['SHIFTED_MONTHLY_ME'] / bin_4['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Bin 5\n",
    "            \n",
    "            # Get where the index is equal to the date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_high['MONTHLY_ME_TOTAL'] = bin_high.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 5], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged ME's in that portfolio on that monthly date\n",
    "            bin_high['weight'] = bin_high['SHIFTED_MONTHLY_ME'] / bin_high['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # NonRD Bin\n",
    "            \n",
    "            # Get where the index is equal to the date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_nonRD['MONTHLY_ME_TOTAL'] = bin_nonRD.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 'NonRD'], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged ME's in that portfolio on that monthly date\n",
    "            bin_nonRD['weight'] = bin_nonRD['SHIFTED_MONTHLY_ME'] / bin_nonRD['MONTHLY_ME_TOTAL']\n",
    "\n",
    "            \n",
    "            # Put dataframes back together\n",
    "            joined_df = pd.concat([bin_low, bin_2, bin_3, bin_4, bin_high, bin_nonRD])\n",
    "\n",
    "            # Make new column with weight * return\n",
    "            joined_df['WEIGHTED_RET'] = joined_df['RET'] * joined_df['weight']\n",
    "\n",
    "            # Calculate portfolio returns by grouping by monthly date and bin to get a total weighted return for that portfolio for that time\n",
    "            # Creates df that is returned that has for every month, each portfolio's total weighted return\n",
    "            portfolio_returns = portfolio_returns.append(joined_df.groupby(['MONTHLY_DATE', 'bin'])['WEIGHTED_RET'].sum().unstack())\n",
    "        \n",
    "        else: \n",
    "            print('Type must be equal or value')\n",
    "\n",
    " \n",
    "    return portfolio_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Calculate Equal-Weighted Returns for R&D and Non-R&D Firms.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equally-Weighted Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform for various time periods\n",
    "results_equal_1981_1999 = make_portfolios(merge, '1981-07-01', '1999-12-31', 'equal')\n",
    "results_equal_2000_2012 = make_portfolios(merge, '2000-01-01', '2012-12-31', 'equal') \n",
    "results_equal_2013_2021 = make_portfolios(merge, '2013-01-01', '2021-12-31', 'equal') \n",
    "results_equal_1981_2012 = make_portfolios(merge, '1981-07-01', '2012-12-31', 'equal')\n",
    "results_equal_1981_2021 = make_portfolios(merge, '1981-07-01', '2021-12-31', 'equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1981 - 1999\n",
    "\n",
    "# Collapses the portfolio_returns df from the function to a series of mean returns for each portfolio for the time range\n",
    "results_equal_1981_1999_summary = pd.DataFrame(results_equal_1981_1999.mean(axis = 0)).T\n",
    "results_equal_1981_1999_summary = results_equal_1981_1999_summary * 100  # Converts to percentage return \n",
    "results_equal_1981_1999_summary = results_equal_1981_1999_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_equal_1981_1999_summary['Time'] = '1981.07 - 1999.12'\n",
    "# set time to index\n",
    "results_equal_1981_1999_summary = results_equal_1981_1999_summary.set_index('Time')\n",
    "\n",
    "\n",
    "# 2000 - 2012\n",
    "\n",
    "# Collapses the portfolio_returns df from the function to a series of mean returns for each portfolio for the time range\n",
    "results_equal_2000_2012_summary = pd.DataFrame(results_equal_2000_2012.mean(axis = 0)).T\n",
    "results_equal_2000_2012_summary = results_equal_2000_2012_summary * 100\n",
    "results_equal_2000_2012_summary = results_equal_2000_2012_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_equal_2000_2012_summary['Time'] = \"2000.01 - 2012.12\"\n",
    "# set time to index\n",
    "results_equal_2000_2012_summary = results_equal_2000_2012_summary.set_index('Time')\n",
    "\n",
    "\n",
    "# 1981 - 2012\n",
    "\n",
    "# Collapses the portfolio_returns df from the function to a series of mean returns for each portfolio for the time range\n",
    "results_equal_1981_2012_summary = pd.DataFrame(results_equal_1981_2012.mean(axis = 0)).T\n",
    "results_equal_1981_2012_summary = results_equal_1981_2012_summary * 100\n",
    "results_equal_1981_2012_summary = results_equal_1981_2012_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_equal_1981_2012_summary['Time'] = \"1981.07 - 2012.12\"\n",
    "# set time to index\n",
    "results_equal_1981_2012_summary = results_equal_1981_2012_summary.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin</th>\n",
       "      <th>Low</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>High</th>\n",
       "      <th>NonRD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981.07 - 2012.12</th>\n",
       "      <td>0.244474</td>\n",
       "      <td>0.592820</td>\n",
       "      <td>0.869259</td>\n",
       "      <td>1.120119</td>\n",
       "      <td>1.769685</td>\n",
       "      <td>0.706033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981.07 - 1999.12</th>\n",
       "      <td>0.242229</td>\n",
       "      <td>0.598276</td>\n",
       "      <td>0.865817</td>\n",
       "      <td>1.122465</td>\n",
       "      <td>1.722986</td>\n",
       "      <td>0.569318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000.01 - 2012.12</th>\n",
       "      <td>0.247645</td>\n",
       "      <td>0.581299</td>\n",
       "      <td>0.873003</td>\n",
       "      <td>1.113901</td>\n",
       "      <td>1.836796</td>\n",
       "      <td>0.900588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin                     Low         2         3         4      High     NonRD\n",
       "Time                                                                         \n",
       "1981.07 - 2012.12  0.244474  0.592820  0.869259  1.120119  1.769685  0.706033\n",
       "1981.07 - 1999.12  0.242229  0.598276  0.865817  1.122465  1.722986  0.569318\n",
       "2000.01 - 2012.12  0.247645  0.581299  0.873003  1.113901  1.836796  0.900588"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all dataframes\n",
    "results_equal_tog = pd.concat([results_equal_1981_2012_summary, results_equal_1981_1999_summary, results_equal_2000_2012_summary])\n",
    "# results_equal_tog.to_csv('results_equal_tog.csv')\n",
    "results_equal_tog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Long-Short Portfolio - CAPM Alpha, FF3 Alpha, and SR (Equal-Weighted)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) CAPM Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols, get zero cost portfolio (High - Low)\n",
    "results_equal_1981_2012 = results_equal_1981_2012.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_equal_1981_2012['H-L'] = results_equal_1981_2012['High'] - results_equal_1981_2012['Low']\n",
    "# Create Year-Month column to merge fama data with so it has the same format\n",
    "results_equal_1981_2012['YEAR_MONTH'] = results_equal_1981_2012.index.year.astype(str) + '-' + results_equal_1981_2012.index.month.astype(str).str.zfill(2)\n",
    "\n",
    "# Merge fama and portfolio returns on Year-Month\n",
    "merged_equal_fama = results_equal_1981_2012.merge(fama_data, left_on = 'YEAR_MONTH', right_on = 'DATE')\n",
    "merged_equal_fama = merged_equal_fama.set_index('YEAR_MONTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     3.012\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):             0.0834\n",
      "Time:                        19:16:25   Log-Likelihood:                 609.49\n",
      "No. Observations:                 378   AIC:                            -1215.\n",
      "Df Residuals:                     376   BIC:                            -1207.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0147      0.003      5.867      0.000       0.010       0.020\n",
      "Mkt-RF         0.0947      0.055      1.736      0.083      -0.013       0.202\n",
      "==============================================================================\n",
      "Omnibus:                      329.265   Durbin-Watson:                   1.519\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10199.761\n",
      "Skew:                           3.495   Prob(JB):                         0.00\n",
      "Kurtosis:                      27.469   Cond. No.                         21.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regressing the H-L on the Mkt-RF\n",
    "X = merged_equal_fama['Mkt-RF']\n",
    "y = merged_equal_fama['H-L']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat = model.tvalues[0]\n",
    "coef = model.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equally Weighted Portfolio Results (1981-2012)\n",
      "\n",
      "Monthly CAPM Alpha: 1.471%\n",
      "t-statistic: 5.867\n"
     ]
    }
   ],
   "source": [
    "print('Equally Weighted Portfolio Results (1981-2012)')\n",
    "print()\n",
    "print('Monthly CAPM Alpha: ' + str(round(coef * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) FF3 Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.233\n",
      "Model:                            OLS   Adj. R-squared:                  0.227\n",
      "Method:                 Least Squares   F-statistic:                     37.96\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           1.96e-21\n",
      "Time:                        19:16:25   Log-Likelihood:                 658.21\n",
      "No. Observations:                 378   AIC:                            -1308.\n",
      "Df Residuals:                     374   BIC:                            -1293.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0144      0.002      6.417      0.000       0.010       0.019\n",
      "Mkt-RF        -0.0034      0.051     -0.068      0.946      -0.103       0.096\n",
      "SMB            0.7773      0.075     10.305      0.000       0.629       0.926\n",
      "HML            0.0841      0.080      1.054      0.292      -0.073       0.241\n",
      "==============================================================================\n",
      "Omnibus:                      202.126   Durbin-Watson:                   1.577\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1898.948\n",
      "Skew:                           2.066   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.173   Cond. No.                         40.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# FF3 Factor alpha\n",
    "# Regressing H-L on Mkt-RF, SMB, and HML\n",
    "X2 = merged_equal_fama[['Mkt-RF', 'SMB', 'HML']]\n",
    "y2 = merged_equal_fama['H-L']\n",
    "X2 = sm.add_constant(X2)\n",
    "model2 = sm.OLS(y2, X2).fit()\n",
    "print(model2.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat2 = model2.tvalues[0]\n",
    "coef2 = model2.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equally Weighted Portfolio Results (1981-2012)\n",
      "\n",
      "Monthly FF3 Alpha: 1.438%\n",
      "t-statistic: 6.417\n"
     ]
    }
   ],
   "source": [
    "print('Equally Weighted Portfolio Results (1981-2012)')\n",
    "print()\n",
    "print('Monthly FF3 Alpha: ' + str(round(coef2 * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Annualized Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe Ratio: 1.089\n"
     ]
    }
   ],
   "source": [
    "# Creating the series of monthly returns of zero cost portfolio \n",
    "long_short = merged_equal_fama['H-L']\n",
    "\n",
    "# Getting the mean and standard deviation of these returns \n",
    "mean_return = long_short.mean()\n",
    "std_dev = long_short.std()\n",
    "\n",
    "# Monthly and annual sharpe ratio\n",
    "monthly_sharpe_ratio = mean_return / std_dev\n",
    "annualized_sharpe_ratio = monthly_sharpe_ratio * np.sqrt(12)\n",
    "print('Annualized Sharpe Ratio:', round(annualized_sharpe_ratio, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Repeat Steps 1, 2 for Value-Weighted Portfolios (Returns and Alphas)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value-Weighted Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform for time periods\n",
    "results_value_1981_1999 = make_portfolios(merge, '1981-07-01', '1999-12-31', 'value')\n",
    "results_value_2000_2012 = make_portfolios(merge, '2000-01-01', '2012-12-31', 'value') \n",
    "results_value_2013_2021 = make_portfolios(merge, '2013-01-01', '2021-12-31', 'value') \n",
    "results_value_1981_2012 = make_portfolios(merge, '1981-07-01', '2012-12-31', 'value')\n",
    "results_value_1981_2021 = make_portfolios(merge, '1981-07-01', '2021-12-31', 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1981 - 1999\n",
    "\n",
    "# Collapses the portfolio_returns df from the function to a series of mean returns for each portfolio for the time range\n",
    "results_value_1981_1999_summary = pd.DataFrame(results_value_1981_1999.mean(axis = 0)).T\n",
    "results_value_1981_1999_summary = results_value_1981_1999_summary * 100     # Converting it to percentage return \n",
    "results_value_1981_1999_summary = results_value_1981_1999_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_1999_summary['Time'] = '1981.07 - 1999.12'\n",
    "# set time to index\n",
    "results_value_1981_1999_summary = results_value_1981_1999_summary.set_index('Time')\n",
    "\n",
    "\n",
    "# 2000 - 2012\n",
    "\n",
    "# Collapses the portfolio_returns df from the function to a series of mean returns for each portfolio for the time range\n",
    "results_value_2000_2012_summary = pd.DataFrame(results_value_2000_2012.mean(axis = 0)).T\n",
    "results_value_2000_2012_summary = results_value_2000_2012_summary * 100\n",
    "results_value_2000_2012_summary = results_value_2000_2012_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_2000_2012_summary['Time'] = \"2000.01 - 2012.12\"\n",
    "# set time to index\n",
    "results_value_2000_2012_summary = results_value_2000_2012_summary.set_index('Time')\n",
    "\n",
    "\n",
    "# 1981 - 2012\n",
    "\n",
    "# Collapses the portfolio_returns df from the function to a series of mean returns for each portfolio for the time range\n",
    "results_value_1981_2012_summary = pd.DataFrame(results_value_1981_2012.mean(axis = 0)).T\n",
    "results_value_1981_2012_summary = results_value_1981_2012_summary * 100\n",
    "results_value_1981_2012_summary = results_value_1981_2012_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_2012_summary['Time'] = \"1981.07 - 2012.12\"\n",
    "# set time to index\n",
    "results_value_1981_2012_summary = results_value_1981_2012_summary.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin</th>\n",
       "      <th>Low</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>High</th>\n",
       "      <th>NonRD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981.07 - 2012.12</th>\n",
       "      <td>0.438976</td>\n",
       "      <td>0.607080</td>\n",
       "      <td>0.664502</td>\n",
       "      <td>0.886940</td>\n",
       "      <td>0.966982</td>\n",
       "      <td>0.551287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981.07 - 1999.12</th>\n",
       "      <td>0.675160</td>\n",
       "      <td>0.994105</td>\n",
       "      <td>1.055652</td>\n",
       "      <td>1.082074</td>\n",
       "      <td>1.193141</td>\n",
       "      <td>0.767481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000.01 - 2012.12</th>\n",
       "      <td>0.100742</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.109926</td>\n",
       "      <td>0.619786</td>\n",
       "      <td>0.646435</td>\n",
       "      <td>0.243628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin                     Low         2         3         4      High     NonRD\n",
       "Time                                                                         \n",
       "1981.07 - 2012.12  0.438976  0.607080  0.664502  0.886940  0.966982  0.551287\n",
       "1981.07 - 1999.12  0.675160  0.994105  1.055652  1.082074  1.193141  0.767481\n",
       "2000.01 - 2012.12  0.100742  0.055259  0.109926  0.619786  0.646435  0.243628"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all dataframes\n",
    "results_value_tog = pd.concat([results_value_1981_2012_summary, results_value_1981_1999_summary, results_value_2000_2012_summary])\n",
    "# results_value_tog.to_csv('value_12.csv')\n",
    "results_value_tog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long-Short Portfolio - CAPM Alpha, FF3 Alpha, and SR (Equal-Weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) CAPM Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols, get zero cost portfolio (High - Low)\n",
    "results_value_1981_2012 = results_value_1981_2012.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_2012['H-L'] = results_value_1981_2012['High'] - results_value_1981_2012['Low']\n",
    "# Create Year-Month column to merge fama data with \n",
    "results_value_1981_2012['YEAR_MONTH'] = results_value_1981_2012.index.year.astype(str) + '-' + results_value_1981_2012.index.month.astype(str).str.zfill(2)\n",
    "\n",
    "# Merge fama and portfolio returns\n",
    "merged_value_fama = results_value_1981_2012.merge(fama_data, left_on = 'YEAR_MONTH', right_on = 'DATE')\n",
    "merged_value_fama = merged_value_fama.set_index('YEAR_MONTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.102\n",
      "Model:                            OLS   Adj. R-squared:                  0.100\n",
      "Method:                 Least Squares   F-statistic:                     42.78\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           2.01e-10\n",
      "Time:                        19:18:38   Log-Likelihood:                 614.77\n",
      "No. Observations:                 378   AIC:                            -1226.\n",
      "Df Residuals:                     376   BIC:                            -1218.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0033      0.002      1.325      0.186      -0.002       0.008\n",
      "Mkt-RF         0.3519      0.054      6.540      0.000       0.246       0.458\n",
      "==============================================================================\n",
      "Omnibus:                      103.840   Durbin-Watson:                   1.810\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              553.103\n",
      "Skew:                           1.048   Prob(JB):                    7.86e-121\n",
      "Kurtosis:                       8.543   Cond. No.                         21.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regressing the H-L on the Mkt-RF\n",
    "X_v = merged_value_fama['Mkt-RF']\n",
    "y_v = merged_value_fama['H-L']\n",
    "X_v = sm.add_constant(X_v)\n",
    "model_v = sm.OLS(y_v, X_v).fit()\n",
    "print(model_v.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat_v = model_v.tvalues[0]\n",
    "coef_v = model_v.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Weighted Portfolio Results (1981-2012)\n",
      "\n",
      "Monthly CAPM Alpha: 0.328%\n",
      "t-statistic: 1.325\n"
     ]
    }
   ],
   "source": [
    "print('Value Weighted Portfolio Results (1981-2012)')\n",
    "print()\n",
    "print('Monthly CAPM Alpha: ' + str(round(coef_v * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat_v, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) FF3 Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.322\n",
      "Model:                            OLS   Adj. R-squared:                  0.316\n",
      "Method:                 Least Squares   F-statistic:                     59.13\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           2.64e-31\n",
      "Time:                        19:18:39   Log-Likelihood:                 667.77\n",
      "No. Observations:                 378   AIC:                            -1328.\n",
      "Df Residuals:                     374   BIC:                            -1312.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0010      0.002      0.469      0.639      -0.003       0.005\n",
      "Mkt-RF         0.3316      0.049      6.722      0.000       0.235       0.429\n",
      "SMB            0.7654      0.074     10.407      0.000       0.621       0.910\n",
      "HML            0.4956      0.078      6.374      0.000       0.343       0.648\n",
      "==============================================================================\n",
      "Omnibus:                       46.483   Durbin-Watson:                   1.918\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              126.137\n",
      "Skew:                           0.577   Prob(JB):                     4.07e-28\n",
      "Kurtosis:                       5.584   Cond. No.                         40.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# FF3 Factor alpha\n",
    "# Regressing H-L on Mkt-RF, SMB, and HML\n",
    "X_v_2 = merged_value_fama[['Mkt-RF', 'SMB', 'HML']]\n",
    "y_v_2 = merged_value_fama['H-L']\n",
    "X_v_2 = sm.add_constant(X_v_2)\n",
    "model_v_2 = sm.OLS(y_v_2, X_v_2).fit()\n",
    "print(model_v_2.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat_v_2 = model_v_2.tvalues[0]\n",
    "coef_v_2 = model_v_2.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Weighted Portfolio Results (1981-2012)\n",
      "\n",
      "Monthly FF3 Alpha: 0.102%\n",
      "t-statistic: 0.469\n"
     ]
    }
   ],
   "source": [
    "print('Value Weighted Portfolio Results (1981-2012)')\n",
    "print()\n",
    "print('Monthly FF3 Alpha: ' + str(round(coef_v_2 * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat_v_2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Annualized Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe Ratio:  0.364\n"
     ]
    }
   ],
   "source": [
    "# Series of monthly zero-cost portfolio returns \n",
    "long_short = merged_value_fama['H-L']\n",
    "\n",
    "# Getting mean and std dev of returns\n",
    "mean_return = long_short.mean()\n",
    "std_dev = long_short.std()\n",
    "\n",
    "# Monthly and annual SR\n",
    "monthly_sharpe_ratio = mean_return / std_dev\n",
    "annualized_sharpe_ratio = monthly_sharpe_ratio * np.sqrt(12)\n",
    "print('Annualized Sharpe Ratio: ', round(annualized_sharpe_ratio, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Repeat Steps 1, 2 for Value-Weighted Portfolios (Returns and Alphas) - Excluding 1000 Largest Firms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same function as was defined above, but now just dropping top 1000 value weighted firms each year before RD and NonRD split\n",
    "\n",
    "def make_portfolios_1000(merge, start_date, end_date, type_weight) :\n",
    "\n",
    "    # Filter for the year\n",
    "    df = merge[(merge['MONTHLY_DATE'] >= start_date) & (merge['MONTHLY_DATE'] <= end_date)]\n",
    "\n",
    "    # Set up empty df for returns\n",
    "    portfolio_returns = pd.DataFrame()\n",
    "    monthly_me = pd.DataFrame()\n",
    "\n",
    "    # Years to loop through in portfolio creation \n",
    "    total_years = df['YEAR'].unique()\n",
    "    \n",
    "    # Sort years \n",
    "    total_years = np.sort(total_years)\n",
    "\n",
    "    # Loop through the years\n",
    "    for year in total_years: \n",
    "       \n",
    "        # Filter for the year\n",
    "        df_year = df[df['YEAR'] == year]\n",
    "\n",
    "        # In df_year, sort by 'ME and remove the top 1000 permnos\n",
    "        df_year = df_year.sort_values(by = 'ME', ascending = False)\n",
    "        # Group by permno and take mean of ME (should have 12 records per permno for each YEAR with same ME value, so mean will return that value)\n",
    "        group_df = df_year.groupby('PERMNO')['ME'].mean()\n",
    "        group_df.sort_values(ascending = False, inplace = True)\n",
    "        \n",
    "        # Get a list of top 1000 permnos in index\n",
    "        top_1000 = group_df.index[:1000]\n",
    "        \n",
    "        # Exclude these permnos\n",
    "        df_year2 = df_year[~df_year['PERMNO'].isin(top_1000)]\n",
    "\n",
    "        # Split into RD and NonRD dfs\n",
    "        rd = df_year2[df_year2['rdc/ME'] > 0]\n",
    "        non_rd = df_year2[df_year2['rdc/ME'] == 0]\n",
    "\n",
    "        # Sort by rdc/ME\n",
    "        rd = rd.sort_values(by = ['rdc/ME'], ascending = False)\n",
    "\n",
    "        # Cut rd firms into 5 bins\n",
    "        rd['bin'] = pd.qcut(rd['rdc/ME'], 5, labels = [1,2,3,4,5])\n",
    "        non_rd['bin'] = 'NonRD'\n",
    "\n",
    "        # Put dataframes back together\n",
    "        joined_df = pd.concat([rd, non_rd])\n",
    "\n",
    "\n",
    "        # Equal weighted portfolio returns \n",
    "        if type_weight == 'equal' : \n",
    "            \n",
    "            # Calculate portfolio returns and add to df\n",
    "            # Grouped by monthly_date and bin to get an average return for each bin for each month in df\n",
    "            # This part will actually NOT get used because the top 1000 dropped is only for value weighted portfolios\n",
    "            portfolio_returns = portfolio_returns.append(joined_df.groupby(['MONTHLY_DATE', 'bin'])['RET'].mean().unstack())    \n",
    "\n",
    "        # Value weighted portfolio returns \n",
    "        elif type_weight == 'value' : \n",
    "            \n",
    "            # Make separate dfs by bin\n",
    "            bin_low = joined_df[joined_df['bin'] == 1]\n",
    "            bin_2 = joined_df[joined_df['bin'] == 2]\n",
    "            bin_3 = joined_df[joined_df['bin'] == 3]\n",
    "            bin_4 = joined_df[joined_df['bin'] == 4]\n",
    "            bin_high = joined_df[joined_df['bin'] == 5]\n",
    "            bin_nonRD = joined_df[joined_df['bin'] == 'NonRD']\n",
    "\n",
    "            # Dataframe of the sum of the lagged ME for proper stocks in each portfolio to use as denominator of weights in each portfolio\n",
    "            # Group by monthly_date and bin, then take sum of shifted monthly ME for that combination and store in the df\n",
    "            monthly_me = monthly_me.append(joined_df.groupby(['MONTHLY_DATE', 'bin'])['SHIFTED_MONTHLY_ME'].sum().unstack()) \n",
    "    \n",
    "            \n",
    "            # Bin 1\n",
    "\n",
    "            # Get where the index is equal to the monthly date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_low['MONTHLY_ME_TOTAL'] = bin_low.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 1], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged MEs in that portfolio on that month_date\n",
    "            bin_low['weight'] = bin_low['SHIFTED_MONTHLY_ME'] / bin_low['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Bin 2\n",
    "            \n",
    "            # Get where the index is equal to the monthly date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_2['MONTHLY_ME_TOTAL'] = bin_2.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 2], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged MEs in that portfolio on that month_date\n",
    "            bin_2['weight'] = bin_2['SHIFTED_MONTHLY_ME'] / bin_2['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Bin 3\n",
    "            \n",
    "            # Get where the index is equal to the monthly date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_3['MONTHLY_ME_TOTAL'] = bin_3.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 3], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged MEs in that portfolio on that month_date\n",
    "            bin_3['weight'] = bin_3['SHIFTED_MONTHLY_ME'] / bin_3['MONTHLY_ME_TOTAL']\n",
    "\n",
    "            \n",
    "            # Bin 4\n",
    "            \n",
    "            # Get where the index is equal to the monthly date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_4['MONTHLY_ME_TOTAL'] = bin_4.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 4], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged MEs in that portfolio on that month_date\n",
    "            bin_4['weight'] = bin_4['SHIFTED_MONTHLY_ME'] / bin_4['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Bin 5\n",
    "\n",
    "            # Get where the index is equal to the monthly date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_high['MONTHLY_ME_TOTAL'] = bin_high.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 5], axis = 1)\n",
    "\n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged MEs in that portfolio on that month_date\n",
    "            bin_high['weight'] = bin_high['SHIFTED_MONTHLY_ME'] / bin_high['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Bin NonRD\n",
    "\n",
    "            # Get where the index is equal to the monthly date and return the value of the summed ME for that monthly date for that bin ; make a new column of this series\n",
    "            # The summed ME will be used as the denominator in the weights calculations later \n",
    "            bin_nonRD['MONTHLY_ME_TOTAL'] = bin_nonRD.apply(lambda x: monthly_me.loc[x['MONTHLY_DATE'], 'NonRD'], axis = 1)\n",
    "            \n",
    "            # Compute the weight for each stock as its lagged ME / sum of lagged MEs in that portfolio on that month_date\n",
    "            bin_nonRD['weight'] = bin_nonRD['SHIFTED_MONTHLY_ME'] / bin_nonRD['MONTHLY_ME_TOTAL']\n",
    "\n",
    "\n",
    "            # Put dataframes back together\n",
    "            joined_df = pd.concat([bin_low, bin_2, bin_3, bin_4, bin_high, bin_nonRD])\n",
    "\n",
    "            # Make new column with weight * return\n",
    "            joined_df['WEIGHTED_RET'] = joined_df['RET'] * joined_df['weight']\n",
    "\n",
    "            # Calculate portfolio returns by grouping by monthly_date and bin and taking the sum of the weighted returns\n",
    "            # Creates df that is indexed by monthly_date and has columns for each bin with the total weighted return for that bin for that month\n",
    "            portfolio_returns = portfolio_returns.append(joined_df.groupby(['MONTHLY_DATE', 'bin'])['WEIGHTED_RET'].sum().unstack())\n",
    "        \n",
    "        else: \n",
    "            print('Type must be equal or value')\n",
    "\n",
    " \n",
    "    return portfolio_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value-Weighted Results (Remove 1000 Largest Firms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform for time periods\n",
    "results_value_1981_1999_drop = make_portfolios_1000(merge, '1981-07-01', '1999-12-31', 'value')\n",
    "results_value_2000_2012_drop = make_portfolios_1000(merge, '2000-01-01', '2012-12-31', 'value') \n",
    "results_value_2013_2021_drop = make_portfolios_1000(merge, '2013-01-01', '2021-12-31', 'value') \n",
    "results_value_1981_2012_drop = make_portfolios_1000(merge, '1981-07-01', '2012-12-31', 'value')\n",
    "results_value_1981_2021_drop = make_portfolios_1000(merge, '1981-07-01', '2021-12-31', 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1981 - 1999\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_value_1981_1999_summary_drop = pd.DataFrame(results_value_1981_1999_drop.mean(axis = 0)).T\n",
    "results_value_1981_1999_summary_drop = results_value_1981_1999_summary_drop * 100   # Converts to percentage returns \n",
    "results_value_1981_1999_summary_drop = results_value_1981_1999_summary_drop.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_1999_summary_drop['Time'] = '1981.07 - 1999.12'\n",
    "# Set time to index\n",
    "results_value_1981_1999_summary_drop = results_value_1981_1999_summary_drop.set_index('Time')\n",
    "\n",
    "\n",
    "# 2000 - 2012\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_value_2000_2012_summary_drop = pd.DataFrame(results_value_2000_2012_drop.mean(axis = 0)).T\n",
    "results_value_2000_2012_summary_drop = results_value_2000_2012_summary_drop * 100\n",
    "results_value_2000_2012_summary_drop = results_value_2000_2012_summary_drop.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_2000_2012_summary_drop['Time'] = \"2000.01 - 2012.12\"\n",
    "# Set time to index\n",
    "results_value_2000_2012_summary_drop = results_value_2000_2012_summary_drop.set_index('Time')\n",
    "\n",
    "\n",
    "# 1981 - 2012\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_value_1981_2012_summary_drop = pd.DataFrame(results_value_1981_2012_drop.mean(axis = 0)).T\n",
    "results_value_1981_2012_summary_drop = results_value_1981_2012_summary_drop * 100\n",
    "results_value_1981_2012_summary_drop = results_value_1981_2012_summary_drop.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_2012_summary_drop['Time'] = \"1981.07 - 2012.12\"\n",
    "# Set time to index\n",
    "results_value_1981_2012_summary_drop = results_value_1981_2012_summary_drop.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin</th>\n",
       "      <th>Low</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>High</th>\n",
       "      <th>NonRD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981.07 - 2012.12</th>\n",
       "      <td>0.317333</td>\n",
       "      <td>0.536762</td>\n",
       "      <td>0.740594</td>\n",
       "      <td>0.872438</td>\n",
       "      <td>1.290774</td>\n",
       "      <td>0.580132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981.07 - 1999.12</th>\n",
       "      <td>0.406568</td>\n",
       "      <td>0.604770</td>\n",
       "      <td>0.853944</td>\n",
       "      <td>1.015888</td>\n",
       "      <td>1.277229</td>\n",
       "      <td>0.496166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000.01 - 2012.12</th>\n",
       "      <td>0.148039</td>\n",
       "      <td>0.443561</td>\n",
       "      <td>0.580614</td>\n",
       "      <td>0.669582</td>\n",
       "      <td>1.307938</td>\n",
       "      <td>0.701900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin                     Low         2         3         4      High     NonRD\n",
       "Time                                                                         \n",
       "1981.07 - 2012.12  0.317333  0.536762  0.740594  0.872438  1.290774  0.580132\n",
       "1981.07 - 1999.12  0.406568  0.604770  0.853944  1.015888  1.277229  0.496166\n",
       "2000.01 - 2012.12  0.148039  0.443561  0.580614  0.669582  1.307938  0.701900"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all dataframes\n",
    "results_value_tog_drop = pd.concat([results_value_1981_2012_summary_drop, results_value_1981_1999_summary_drop, results_value_2000_2012_summary_drop])\n",
    "# results_value_tog_drop.to_csv('results_value_tog_drop.csv')\n",
    "results_value_tog_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long-Short Portfolio - CAPM Alpha, FF3 Alpha, and SR (Remove 1000 Largest Firms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) CAPM Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols, get zero cost portfolio (High - Low)\n",
    "results_value_1981_2012_drop = results_value_1981_2012_drop.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_2012_drop['H-L'] = results_value_1981_2012_drop['High'] - results_value_1981_2012_drop['Low']\n",
    "# Create Year-Month column to merge fama data with \n",
    "results_value_1981_2012_drop['YEAR_MONTH'] = results_value_1981_2012_drop.index.year.astype(str) + '-' + results_value_1981_2012_drop.index.month.astype(str).str.zfill(2)\n",
    "\n",
    "# Merge fama and portfolio returns\n",
    "merged_value_fama_drop = results_value_1981_2012_drop.merge(fama_data, left_on = 'YEAR_MONTH', right_on = 'DATE')\n",
    "merged_value_fama_drop = merged_value_fama_drop.set_index('YEAR_MONTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.045\n",
      "Model:                            OLS   Adj. R-squared:                  0.042\n",
      "Method:                 Least Squares   F-statistic:                     17.53\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           3.52e-05\n",
      "Time:                        19:20:26   Log-Likelihood:                 651.62\n",
      "No. Observations:                 378   AIC:                            -1299.\n",
      "Df Residuals:                     376   BIC:                            -1291.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0086      0.002      3.821      0.000       0.004       0.013\n",
      "Mkt-RF         0.2043      0.049      4.187      0.000       0.108       0.300\n",
      "==============================================================================\n",
      "Omnibus:                      129.838   Durbin-Watson:                   1.681\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              623.854\n",
      "Skew:                           1.396   Prob(JB):                    3.40e-136\n",
      "Kurtosis:                       8.641   Cond. No.                         21.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regressing the H-L on the Mkt-RF\n",
    "X_v_drop = merged_value_fama_drop['Mkt-RF']\n",
    "y_v_drop = merged_value_fama_drop['H-L']\n",
    "X_v_drop = sm.add_constant(X_v_drop)\n",
    "model_v_drop = sm.OLS(y_v_drop, X_v_drop).fit()\n",
    "print(model_v_drop.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat_v_drop = model_v_drop.tvalues[0]\n",
    "coef_v_drop = model_v_drop.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Weighted Portfolio Results (1981-2012) with top 1000 Firms Dropped\n",
      "\n",
      "Monthly CAPM Alpha: 0.857%\n",
      "t-statistic: 3.821\n"
     ]
    }
   ],
   "source": [
    "print('Value Weighted Portfolio Results (1981-2012) with top 1000 Firms Dropped')\n",
    "print()\n",
    "print('Monthly CAPM Alpha: ' + str(round(coef_v_drop * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat_v_drop, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) FF3 Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.150\n",
      "Model:                            OLS   Adj. R-squared:                  0.143\n",
      "Method:                 Least Squares   F-statistic:                     21.99\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           3.88e-13\n",
      "Time:                        19:20:26   Log-Likelihood:                 673.71\n",
      "No. Observations:                 378   AIC:                            -1339.\n",
      "Df Residuals:                     374   BIC:                            -1324.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0080      0.002      3.717      0.000       0.004       0.012\n",
      "Mkt-RF         0.1566      0.049      3.225      0.001       0.061       0.252\n",
      "SMB            0.4928      0.072      6.807      0.000       0.350       0.635\n",
      "HML            0.1315      0.077      1.718      0.087      -0.019       0.282\n",
      "==============================================================================\n",
      "Omnibus:                      120.030   Durbin-Watson:                   1.756\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              501.855\n",
      "Skew:                           1.327   Prob(JB):                    1.06e-109\n",
      "Kurtosis:                       7.981   Cond. No.                         40.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# FF3 Factor alpha\n",
    "# Regressing H-L on Mkt-RF, SMB, and HML\n",
    "X_v_2_drop = merged_value_fama_drop[['Mkt-RF', 'SMB', 'HML']]\n",
    "y_v_2_drop = merged_value_fama_drop['H-L']\n",
    "X_v_2_drop = sm.add_constant(X_v_2_drop)\n",
    "model_v_2_drop = sm.OLS(y_v_2_drop, X_v_2_drop).fit()\n",
    "print(model_v_2_drop.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat_v_2_drop = model_v_2_drop.tvalues[0]\n",
    "coef_v_2_drop = model_v_2_drop.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Weighted Portfolio Results (1981-2012) with top 1000 Firms Dropped\n",
      "\n",
      "Monthly FF3 Alpha: 0.799%\n",
      "t-statistic: 3.717\n"
     ]
    }
   ],
   "source": [
    "print('Value Weighted Portfolio Results (1981-2012) with top 1000 Firms Dropped')\n",
    "print()\n",
    "print('Monthly FF3 Alpha: ' + str(round(coef_v_2_drop * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat_v_2_drop, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Annualized Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe Ratio:  0.763\n"
     ]
    }
   ],
   "source": [
    "# Series of zero cost monthly portfolio returns\n",
    "long_short_drop = merged_value_fama_drop['H-L']\n",
    "\n",
    "# Get mean and stdev of those returns\n",
    "mean_return_drop = long_short_drop.mean()\n",
    "std_dev_drop = long_short_drop.std()\n",
    "\n",
    "# Monthly and annualized SR\n",
    "monthly_sharpe_ratio_drop = mean_return_drop / std_dev_drop\n",
    "annualized_sharpe_ratio_drop = monthly_sharpe_ratio_drop * np.sqrt(12)\n",
    "print('Annualized Sharpe Ratio: ', round(annualized_sharpe_ratio_drop, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Repeat Steps 1 - 4 through December 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Calculate Equal-Weighted Returns for R&D and Non-R&D Firms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin</th>\n",
       "      <th>Low</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>High</th>\n",
       "      <th>NonRD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981.07 - 2021.12</th>\n",
       "      <td>0.393994</td>\n",
       "      <td>0.715339</td>\n",
       "      <td>1.033662</td>\n",
       "      <td>1.188898</td>\n",
       "      <td>1.722929</td>\n",
       "      <td>0.761205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981.07 - 1999.12</th>\n",
       "      <td>0.242229</td>\n",
       "      <td>0.598276</td>\n",
       "      <td>0.865817</td>\n",
       "      <td>1.122465</td>\n",
       "      <td>1.722986</td>\n",
       "      <td>0.569318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000.01 - 2012.12</th>\n",
       "      <td>0.247645</td>\n",
       "      <td>0.581299</td>\n",
       "      <td>0.873003</td>\n",
       "      <td>1.113901</td>\n",
       "      <td>1.836796</td>\n",
       "      <td>0.900588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.01 - 2021.12</th>\n",
       "      <td>0.917313</td>\n",
       "      <td>1.144521</td>\n",
       "      <td>1.609046</td>\n",
       "      <td>1.427567</td>\n",
       "      <td>1.559924</td>\n",
       "      <td>0.954307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin                     Low         2         3         4      High     NonRD\n",
       "Time                                                                         \n",
       "1981.07 - 2021.12  0.393994  0.715339  1.033662  1.188898  1.722929  0.761205\n",
       "1981.07 - 1999.12  0.242229  0.598276  0.865817  1.122465  1.722986  0.569318\n",
       "2000.01 - 2012.12  0.247645  0.581299  0.873003  1.113901  1.836796  0.900588\n",
       "2013.01 - 2021.12  0.917313  1.144521  1.609046  1.427567  1.559924  0.954307"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1981 - 2021\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_equal_1981_2021_summary = pd.DataFrame(results_equal_1981_2021.mean(axis = 0)).T\n",
    "results_equal_1981_2021_summary = results_equal_1981_2021_summary * 100\n",
    "results_equal_1981_2021_summary = results_equal_1981_2021_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_equal_1981_2021_summary['Time'] = '1981.07 - 2021.12'\n",
    "# Set time to index\n",
    "results_equal_1981_2021_summary = results_equal_1981_2021_summary.set_index('Time')\n",
    "\n",
    "\n",
    "# 2013 - 2021\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_equal_2013_2021_summary = pd.DataFrame(results_equal_2013_2021.mean(axis = 0)).T\n",
    "results_equal_2013_2021_summary = results_equal_2013_2021_summary * 100\n",
    "results_equal_2013_2021_summary = results_equal_2013_2021_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_equal_2013_2021_summary['Time'] = '2013.01 - 2021.12'\n",
    "# Set time to index\n",
    "results_equal_2013_2021_summary = results_equal_2013_2021_summary.set_index('Time')\n",
    "\n",
    "\n",
    "# Concatenate all dataframes\n",
    "results_equal_tog2 = pd.concat([results_equal_1981_2021_summary, results_equal_1981_1999_summary, results_equal_2000_2012_summary, results_equal_2013_2021_summary])\n",
    "# results_equal_tog2.to_csv('results_equal_tog21.csv')\n",
    "results_equal_tog2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Long-Short Portfolio - CAPM Alpha, FF3 Alpha, and SR (Equal-Weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) CAPM Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols and get zero cost portfolio (High - Low)\n",
    "results_equal_1981_2021 = results_equal_1981_2021.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_equal_1981_2021['H-L'] = results_equal_1981_2021['High'] - results_equal_1981_2021['Low']\n",
    "# Create Year-Month column to merge fama data with  \n",
    "results_equal_1981_2021['YEAR_MONTH'] = results_equal_1981_2021.index.year.astype(str) + '-' + results_equal_1981_2021.index.month.astype(str).str.zfill(2)\n",
    "\n",
    "# Merge fama and portfolio returns\n",
    "merged_equal_fama_5 = results_equal_1981_2021.merge(fama_data, left_on = 'YEAR_MONTH', right_on = 'DATE')\n",
    "merged_equal_fama_5 = merged_equal_fama_5.set_index('YEAR_MONTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.012\n",
      "Model:                            OLS   Adj. R-squared:                  0.010\n",
      "Method:                 Least Squares   F-statistic:                     5.789\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):             0.0165\n",
      "Time:                        19:20:26   Log-Likelihood:                 782.85\n",
      "No. Observations:                 486   AIC:                            -1562.\n",
      "Df Residuals:                     484   BIC:                            -1553.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0124      0.002      5.577      0.000       0.008       0.017\n",
      "Mkt-RF         0.1186      0.049      2.406      0.016       0.022       0.215\n",
      "==============================================================================\n",
      "Omnibus:                      360.906   Durbin-Watson:                   1.535\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8773.981\n",
      "Skew:                           2.922   Prob(JB):                         0.00\n",
      "Kurtosis:                      22.978   Cond. No.                         22.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regressing the H-L on the Mkt-RF\n",
    "X_5 = merged_equal_fama_5['Mkt-RF']\n",
    "y_5 = merged_equal_fama_5['H-L']\n",
    "X_5 = sm.add_constant(X_5)\n",
    "model_5 = sm.OLS(y_5, X_5).fit()\n",
    "print(model_5.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat_5 = model_5.tvalues[0]\n",
    "coef_5 = model_5.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equally Weighted Portfolio Results (1981-2021)\n",
      "\n",
      "Monthly CAPM Alpha: 1.242%\n",
      "t-statistic: 5.577\n"
     ]
    }
   ],
   "source": [
    "print('Equally Weighted Portfolio Results (1981-2021)')\n",
    "print()\n",
    "print('Monthly CAPM Alpha: ' + str(round(coef_5 * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat_5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) FF3 Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.229\n",
      "Model:                            OLS   Adj. R-squared:                  0.225\n",
      "Method:                 Least Squares   F-statistic:                     47.83\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           4.50e-27\n",
      "Time:                        19:20:27   Log-Likelihood:                 843.28\n",
      "No. Observations:                 486   AIC:                            -1679.\n",
      "Df Residuals:                     482   BIC:                            -1662.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0127      0.002      6.426      0.000       0.009       0.017\n",
      "Mkt-RF         0.0033      0.045      0.073      0.942      -0.086       0.092\n",
      "SMB            0.7840      0.068     11.530      0.000       0.650       0.918\n",
      "HML            0.0306      0.067      0.460      0.645      -0.100       0.161\n",
      "==============================================================================\n",
      "Omnibus:                      203.351   Durbin-Watson:                   1.594\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1434.102\n",
      "Skew:                           1.658   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.735   Cond. No.                         37.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# FF3 Factor alpha\n",
    "# Regressing H-L on Mkt-RF, SMB, and HML\n",
    "X2_5 = merged_equal_fama_5[['Mkt-RF', 'SMB', 'HML']]\n",
    "y2_5 = merged_equal_fama_5['H-L']\n",
    "X2_5 = sm.add_constant(X2_5)\n",
    "model2_5 = sm.OLS(y2_5, X2_5).fit()\n",
    "print(model2_5.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat2_5 = model2_5.tvalues[0]\n",
    "coef2_5 = model2_5.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equally Weighted Portfolio Results (1981-2021)\n",
      "\n",
      "Monthly FF3 Alpha: 1.273%\n",
      "t-statistic: 6.426\n"
     ]
    }
   ],
   "source": [
    "print('Equally Weighted Portfolio Results (1981-2021)')\n",
    "print()\n",
    "print('Monthly FF3 Alpha: ' + str(round(coef2_5 * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat2_5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Annualized Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe Ratio: 0.946\n"
     ]
    }
   ],
   "source": [
    "# Series of zero cost monthly portfolio returns\n",
    "long_short_5 = merged_equal_fama_5['H-L']\n",
    "\n",
    "# Get mean and stdev of those returns\n",
    "mean_return_5 = long_short_5.mean()\n",
    "std_dev_5 = long_short_5.std()\n",
    "\n",
    "# Monthly and annualized SR\n",
    "monthly_sharpe_ratio_5 = mean_return_5 / std_dev_5\n",
    "annualized_sharpe_ratio_5 = monthly_sharpe_ratio_5 * np.sqrt(12)\n",
    "\n",
    "print('Annualized Sharpe Ratio:', round(annualized_sharpe_ratio_5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Repeat Steps 1, 2 for Value-Weighted Portfolios (Returns and Alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value-Weighted Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin</th>\n",
       "      <th>Low</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>High</th>\n",
       "      <th>NonRD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981.07 - 2021.12</th>\n",
       "      <td>0.552896</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.858163</td>\n",
       "      <td>1.058458</td>\n",
       "      <td>1.127225</td>\n",
       "      <td>0.630808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981.07 - 1999.12</th>\n",
       "      <td>0.675160</td>\n",
       "      <td>0.994105</td>\n",
       "      <td>1.055652</td>\n",
       "      <td>1.082074</td>\n",
       "      <td>1.193141</td>\n",
       "      <td>0.767481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000.01 - 2012.12</th>\n",
       "      <td>0.100742</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.109926</td>\n",
       "      <td>0.619786</td>\n",
       "      <td>0.646435</td>\n",
       "      <td>0.243628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.01 - 2021.12</th>\n",
       "      <td>0.951615</td>\n",
       "      <td>1.593113</td>\n",
       "      <td>1.534927</td>\n",
       "      <td>1.659034</td>\n",
       "      <td>1.688513</td>\n",
       "      <td>0.909129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin                     Low         2         3         4      High     NonRD\n",
       "Time                                                                         \n",
       "1981.07 - 2021.12  0.552896  0.826087  0.858163  1.058458  1.127225  0.630808\n",
       "1981.07 - 1999.12  0.675160  0.994105  1.055652  1.082074  1.193141  0.767481\n",
       "2000.01 - 2012.12  0.100742  0.055259  0.109926  0.619786  0.646435  0.243628\n",
       "2013.01 - 2021.12  0.951615  1.593113  1.534927  1.659034  1.688513  0.909129"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1981 - 2021\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_value_1981_2021_summary = pd.DataFrame(results_value_1981_2021.mean(axis = 0)).T\n",
    "results_value_1981_2021_summary = results_value_1981_2021_summary * 100\n",
    "results_value_1981_2021_summary = results_value_1981_2021_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_2021_summary['Time'] = '1981.07 - 2021.12'\n",
    "# Set time to index\n",
    "results_value_1981_2021_summary = results_value_1981_2021_summary.set_index('Time')\n",
    "\n",
    "\n",
    "# 2013 - 2021\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_value_2013_2021_summary = pd.DataFrame(results_value_2013_2021.mean(axis = 0)).T\n",
    "results_value_2013_2021_summary = results_value_2013_2021_summary * 100\n",
    "results_value_2013_2021_summary = results_value_2013_2021_summary.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_2013_2021_summary['Time'] = '2013.01 - 2021.12'\n",
    "# Set time to index\n",
    "results_value_2013_2021_summary = results_value_2013_2021_summary.set_index('Time')\n",
    "\n",
    "\n",
    "# Concatenate all dataframes\n",
    "results_value_tog2_5 = pd.concat([results_value_1981_2021_summary, results_value_1981_1999_summary, results_value_2000_2012_summary, results_value_2013_2021_summary])\n",
    "# results_value_tog2_5.to_csv('results_value_tog21_5.csv')\n",
    "results_value_tog2_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) CAPM Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols and get zero cost portfolio (High - Low)\n",
    "results_value_1981_2021 = results_value_1981_2021.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_2021['H-L'] = results_value_1981_2021['High'] - results_value_1981_2021['Low']\n",
    "# Create Year-Month column to merge fama data with\n",
    "results_value_1981_2021['YEAR_MONTH'] = results_value_1981_2021.index.year.astype(str) + '-' + results_value_1981_2021.index.month.astype(str).str.zfill(2)\n",
    "\n",
    "# Merge fama and portfolio returns\n",
    "merged_value_fama_5_a = results_value_1981_2021.merge(fama_data, left_on = 'YEAR_MONTH', right_on = 'DATE')\n",
    "merged_value_fama_5_a = merged_value_fama_5_a.set_index('YEAR_MONTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.104\n",
      "Model:                            OLS   Adj. R-squared:                  0.102\n",
      "Method:                 Least Squares   F-statistic:                     56.29\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           3.02e-13\n",
      "Time:                        19:20:27   Log-Likelihood:                 802.66\n",
      "No. Observations:                 486   AIC:                            -1601.\n",
      "Df Residuals:                     484   BIC:                            -1593.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0031      0.002      1.465      0.144      -0.001       0.007\n",
      "Mkt-RF         0.3550      0.047      7.503      0.000       0.262       0.448\n",
      "==============================================================================\n",
      "Omnibus:                      123.571   Durbin-Watson:                   1.882\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              640.117\n",
      "Skew:                           1.002   Prob(JB):                    1.00e-139\n",
      "Kurtosis:                       8.253   Cond. No.                         22.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regressing the H-L on the Mkt-RF\n",
    "X_5_a = merged_value_fama_5_a['Mkt-RF']\n",
    "y_5_a = merged_value_fama_5_a['H-L']\n",
    "X_5_a = sm.add_constant(X_5_a)\n",
    "model_5_a = sm.OLS(y_5_a, X_5_a).fit()\n",
    "print(model_5_a.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat_5_a = model_5_a.tvalues[0]\n",
    "coef_5_a = model_5_a.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Weighted Portfolio Results (1981-2021)\n",
      "\n",
      "Monthly CAPM Alpha: 0.313%\n",
      "t-statistic: 1.465\n"
     ]
    }
   ],
   "source": [
    "print('Value Weighted Portfolio Results (1981-2021)')\n",
    "print()\n",
    "print('Monthly CAPM Alpha: ' + str(round(coef_5_a * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat_5_a, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) FF3 Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.343\n",
      "Model:                            OLS   Adj. R-squared:                  0.339\n",
      "Method:                 Least Squares   F-statistic:                     84.06\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           9.34e-44\n",
      "Time:                        19:20:27   Log-Likelihood:                 878.18\n",
      "No. Observations:                 486   AIC:                            -1748.\n",
      "Df Residuals:                     482   BIC:                            -1732.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0021      0.002      1.158      0.247      -0.001       0.006\n",
      "Mkt-RF         0.2969      0.042      7.040      0.000       0.214       0.380\n",
      "SMB            0.7766      0.063     12.271      0.000       0.652       0.901\n",
      "HML            0.4503      0.062      7.266      0.000       0.329       0.572\n",
      "==============================================================================\n",
      "Omnibus:                       48.822   Durbin-Watson:                   2.023\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              136.539\n",
      "Skew:                           0.474   Prob(JB):                     2.24e-30\n",
      "Kurtosis:                       5.417   Cond. No.                         37.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# FF3 Factor alpha\n",
    "# Regressing H-L on Mkt-RF, SMB, and HML\n",
    "X2_5_a = merged_value_fama_5_a[['Mkt-RF', 'SMB', 'HML']]\n",
    "y2_5_a = merged_value_fama_5_a['H-L']\n",
    "X2_5_a = sm.add_constant(X2_5_a)\n",
    "model2_5_a = sm.OLS(y2_5_a, X2_5_a).fit()\n",
    "print(model2_5_a.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat2_5_a = model2_5_a.tvalues[0]\n",
    "coef2_5_a = model2_5_a.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Weighted Portfolio Results (1981-2021)\n",
      "\n",
      "Monthly FF3 Alpha: 0.214%\n",
      "t-statistic: 1.158\n"
     ]
    }
   ],
   "source": [
    "print('Value Weighted Portfolio Results (1981-2021)')\n",
    "print()\n",
    "print('Monthly FF3 Alpha: ' + str(round(coef2_5_a * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat2_5_a, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Annualized Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe Ratio: 0.405\n"
     ]
    }
   ],
   "source": [
    "# Series of zero cost monthly portfolio returns\n",
    "long_short_5_a = merged_value_fama_5_a['H-L']\n",
    "\n",
    "# Get mean and stdev of those returns\n",
    "mean_return_5_a = long_short_5_a.mean()\n",
    "std_dev_5_a = long_short_5_a.std()\n",
    "\n",
    "# Monthly and annualized SR\n",
    "monthly_sharpe_ratio_5_a = mean_return_5_a / std_dev_5_a\n",
    "annualized_sharpe_ratio_5_a = monthly_sharpe_ratio_5_a * np.sqrt(12)\n",
    "\n",
    "print('Annualized Sharpe Ratio:', round(annualized_sharpe_ratio_5_a, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Repeat Steps 1, 2 for Value-Weighted Portfolios (Returns and Alphas) - Excluding 1000 Largest Firms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value Weighted Returns (Remove 1000 Largest Firms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin</th>\n",
       "      <th>Low</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>High</th>\n",
       "      <th>NonRD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981.07 - 2021.12</th>\n",
       "      <td>0.484157</td>\n",
       "      <td>0.703383</td>\n",
       "      <td>0.890791</td>\n",
       "      <td>1.069143</td>\n",
       "      <td>1.450758</td>\n",
       "      <td>0.614514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981.07 - 1999.12</th>\n",
       "      <td>0.406568</td>\n",
       "      <td>0.604770</td>\n",
       "      <td>0.853944</td>\n",
       "      <td>1.015888</td>\n",
       "      <td>1.277229</td>\n",
       "      <td>0.496166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000.01 - 2012.12</th>\n",
       "      <td>0.148039</td>\n",
       "      <td>0.443561</td>\n",
       "      <td>0.580614</td>\n",
       "      <td>0.669582</td>\n",
       "      <td>1.307938</td>\n",
       "      <td>0.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013.01 - 2021.12</th>\n",
       "      <td>1.076466</td>\n",
       "      <td>1.287528</td>\n",
       "      <td>1.413665</td>\n",
       "      <td>1.758713</td>\n",
       "      <td>2.011405</td>\n",
       "      <td>0.735221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin                     Low         2         3         4      High     NonRD\n",
       "Time                                                                         \n",
       "1981.07 - 2021.12  0.484157  0.703383  0.890791  1.069143  1.450758  0.614514\n",
       "1981.07 - 1999.12  0.406568  0.604770  0.853944  1.015888  1.277229  0.496166\n",
       "2000.01 - 2012.12  0.148039  0.443561  0.580614  0.669582  1.307938  0.701900\n",
       "2013.01 - 2021.12  1.076466  1.287528  1.413665  1.758713  2.011405  0.735221"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1981 - 2021\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_value_1981_2021_summary_drop = pd.DataFrame(results_value_1981_2021_drop.mean(axis = 0)).T\n",
    "results_value_1981_2021_summary_drop = results_value_1981_2021_summary_drop * 100\n",
    "results_value_1981_2021_summary_drop = results_value_1981_2021_summary_drop.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_2021_summary_drop['Time'] = '1981.07 - 2021.12'\n",
    "# Set time to index\n",
    "results_value_1981_2021_summary_drop = results_value_1981_2021_summary_drop.set_index('Time')\n",
    "\n",
    "\n",
    "# 2013 - 2021\n",
    "\n",
    "# Collapses the portolio_returns df into a series of mean returns for each portfolio for time period\n",
    "results_value_2013_2021_summary_drop = pd.DataFrame(results_value_2013_2021_drop.mean(axis = 0)).T\n",
    "results_value_2013_2021_summary_drop = results_value_2013_2021_summary_drop * 100\n",
    "results_value_2013_2021_summary_drop = results_value_2013_2021_summary_drop.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_2013_2021_summary_drop['Time'] = '2013.01 - 2021.12'\n",
    "# Set time to index\n",
    "results_value_2013_2021_summary_drop = results_value_2013_2021_summary_drop.set_index('Time')\n",
    "\n",
    "\n",
    "# Concatenate all dataframes\n",
    "results_value_tog2_5_drop = pd.concat([results_value_1981_2021_summary_drop, results_value_1981_1999_summary_drop, results_value_2000_2012_summary_drop, results_value_2013_2021_summary_drop])\n",
    "# results_value_tog2_5_drop.to_csv('results_value_tog21_5_drop.csv')\n",
    "results_value_tog2_5_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) CAPM Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols and get zero cost portfolio (High - Low)\n",
    "results_value_1981_2021_drop = results_value_1981_2021_drop.rename(columns = {1: 'Low', 5: 'High'})\n",
    "results_value_1981_2021_drop['H-L'] = results_value_1981_2021_drop['High'] - results_value_1981_2021_drop['Low']\n",
    "# Create Year-Month column to merge fama data with\n",
    "results_value_1981_2021_drop['YEAR_MONTH'] = results_value_1981_2021_drop.index.year.astype(str) + '-' + results_value_1981_2021_drop.index.month.astype(str).str.zfill(2)\n",
    "\n",
    "# merge fama and portfolio returns\n",
    "merged_value_fama_drop_5 = results_value_1981_2021_drop.merge(fama_data, left_on = 'YEAR_MONTH', right_on = 'DATE')\n",
    "merged_value_fama_drop_5 = merged_value_fama_drop_5.set_index('YEAR_MONTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.042\n",
      "Model:                            OLS   Adj. R-squared:                  0.040\n",
      "Method:                 Least Squares   F-statistic:                     20.96\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           5.98e-06\n",
      "Time:                        19:20:27   Log-Likelihood:                 827.54\n",
      "No. Observations:                 486   AIC:                            -1651.\n",
      "Df Residuals:                     484   BIC:                            -1643.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0082      0.002      4.014      0.000       0.004       0.012\n",
      "Mkt-RF         0.2058      0.045      4.578      0.000       0.117       0.294\n",
      "==============================================================================\n",
      "Omnibus:                      149.804   Durbin-Watson:                   1.808\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              742.930\n",
      "Skew:                           1.263   Prob(JB):                    4.73e-162\n",
      "Kurtosis:                       8.505   Cond. No.                         22.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Regressing the H-L on the Mkt-RF\n",
    "X_v_drop_5 = merged_value_fama_drop_5['Mkt-RF']\n",
    "y_v_drop_5 = merged_value_fama_drop_5['H-L']\n",
    "X_v_drop_5 = sm.add_constant(X_v_drop_5)\n",
    "model_v_drop_5 = sm.OLS(y_v_drop_5, X_v_drop_5).fit()\n",
    "print(model_v_drop_5.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat_v_drop_5 = model_v_drop_5.tvalues[0]\n",
    "coef_v_drop_5 = model_v_drop_5.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Weighted Portfolio Results (1981-2021) with top 1000 Firms Dropped\n",
      "\n",
      "Monthly CAPM Alpha: 0.815%\n",
      "t-statistic: 4.014\n"
     ]
    }
   ],
   "source": [
    "print('Value Weighted Portfolio Results (1981-2021) with top 1000 Firms Dropped')\n",
    "print()\n",
    "print('Monthly CAPM Alpha: ' + str(round(coef_v_drop_5 * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat_v_drop_5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) FF3 Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    H-L   R-squared:                       0.140\n",
      "Model:                            OLS   Adj. R-squared:                  0.135\n",
      "Method:                 Least Squares   F-statistic:                     26.25\n",
      "Date:                Tue, 22 Nov 2022   Prob (F-statistic):           9.65e-16\n",
      "Time:                        19:20:27   Log-Likelihood:                 854.02\n",
      "No. Observations:                 486   AIC:                            -1700.\n",
      "Df Residuals:                     482   BIC:                            -1683.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0082      0.002      4.208      0.000       0.004       0.012\n",
      "Mkt-RF         0.1414      0.044      3.190      0.002       0.054       0.228\n",
      "SMB            0.4953      0.067      7.446      0.000       0.365       0.626\n",
      "HML            0.0822      0.065      1.263      0.207      -0.046       0.210\n",
      "==============================================================================\n",
      "Omnibus:                      119.485   Durbin-Watson:                   1.857\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              492.242\n",
      "Skew:                           1.040   Prob(JB):                    1.29e-107\n",
      "Kurtosis:                       7.470   Cond. No.                         37.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# FF3 Factor alpha\n",
    "# Regressing H-L on Mkt-RF, SMB, and HML\n",
    "X_v_2_drop_5 = merged_value_fama_drop_5[['Mkt-RF', 'SMB', 'HML']]\n",
    "y_v_2_drop_5 = merged_value_fama_drop_5['H-L']\n",
    "X_v_2_drop_5 = sm.add_constant(X_v_2_drop_5)\n",
    "model_v_2_drop_5 = sm.OLS(y_v_2_drop_5, X_v_2_drop_5).fit()\n",
    "print(model_v_2_drop_5.summary())\n",
    "\n",
    "# T stat and coeff on the constant\n",
    "t_stat_v_2_drop_5 = model_v_2_drop_5.tvalues[0]\n",
    "coef_v_2_drop_5 = model_v_2_drop_5.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Weighted Portfolio Results (1981-2021) with top 1000 Firms Dropped\n",
      "\n",
      "Monthly FF3 Alpha: 0.815%\n",
      "t-statistic: 4.208\n"
     ]
    }
   ],
   "source": [
    "print('Value Weighted Portfolio Results (1981-2021) with top 1000 Firms Dropped')\n",
    "print()\n",
    "print('Monthly FF3 Alpha: ' + str(round(coef_v_2_drop_5 * 100, 3)) + '%')\n",
    "print('t-statistic:', round(t_stat_v_2_drop_5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Annualized Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Sharpe Ratio:  0.743\n"
     ]
    }
   ],
   "source": [
    "# Series of monthly returns for the long-short portfolio\n",
    "long_short_drop_5 = merged_value_fama_drop_5['H-L']\n",
    "\n",
    "# Mean return and stdev of returns\n",
    "mean_return_drop_5 = long_short_drop_5.mean()\n",
    "std_dev_drop_5 = long_short_drop_5.std()\n",
    "\n",
    "# Monthly SR and annualized SR\n",
    "monthly_sharpe_ratio_drop_5 = mean_return_drop_5 / std_dev_drop_5\n",
    "annualized_sharpe_ratio_drop_5 = monthly_sharpe_ratio_drop_5 * np.sqrt(12)\n",
    "print('Annualized Sharpe Ratio: ', round(annualized_sharpe_ratio_drop_5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d16231084e55caf206c5dcf9a407b9830a1cccf4c1bfe921ab5cc3709ab824f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
